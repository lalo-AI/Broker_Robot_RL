{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOaZEBK5nIYPLfELu8io8q3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Misión 3: Entrenando el agente inteligente"],"metadata":{"id":"6-bLvJapcSMV"}},{"cell_type":"markdown","source":["## Recapitulación de la misión anterior"],"metadata":{"id":"uvxivziLcbC-"}},{"cell_type":"code","source":["!pip install plotly\n","!pip install --upgrade pandas\n","!pip install --upgrade pandas-datareader"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_cGCRvRb5j2","executionInfo":{"status":"ok","timestamp":1663056167179,"user_tz":300,"elapsed":21386,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"3eba7b7e-9031-4975-cc5c-f67ca6269c2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.2.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n","Collecting pandas-datareader\n","  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n","\u001b[K     |████████████████████████████████| 109 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.9.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.23.0)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.3.5)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2022.2.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n","Installing collected packages: pandas-datareader\n","  Attempting uninstall: pandas-datareader\n","    Found existing installation: pandas-datareader 0.9.0\n","    Uninstalling pandas-datareader-0.9.0:\n","      Successfully uninstalled pandas-datareader-0.9.0\n","Successfully installed pandas-datareader-0.10.0\n"]}]},{"cell_type":"code","source":["#!pip install tensorflow-gpu"],"metadata":{"id":"WdlB9Z4uemZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paquetes básicos para el análisis de datos\n","import math\n","import random\n","import numpy as np\n","import pandas as pd\n","import pandas_datareader as data_reader\n","from collections import deque\n","\n","# Paquetes especializados en graficación e interacción\n","%matplotlib notebook\n","import matplotlib.pyplot as plt\n","import plotly.graph_objects as go\n","import plotly.express as px\n","from plotly.subplots import make_subplots\n","\n","# Paquete especializado en tensores y, sobre todo, en redes neuronales\n","import tensorflow as tf\n","from tensorflow import keras"],"metadata":{"id":"e1zh55-LcQi1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dataset_loader(stock_name, clip_data, train_portion=0.5):\n","    full_dataset = data_reader.DataReader(\n","        stock_name, data_source=\"yahoo\").iloc[-clip_data:]\n","\n","    data_start_date = str(full_dataset.index[0])\n","    data_end_date = str(full_dataset.index[-1])\n","\n","    data = full_dataset['Close']\n","    data_samples = len(data)\n","    data_mid_date = str(full_dataset.index[int(data_samples * train_portion)])\n","\n","    train_data = data[:data_mid_date]\n","    test_data = data[data_mid_date:]\n","\n","    fmt_str = \"{} <---[{}]---> {} <---[{}]---> {}\"\n","    print(\"Timeline:\\n\", fmt_str.format(\n","        data_start_date.split()[0], len(train_data),\n","        data_mid_date.split()[0], len(test_data),\n","        data_end_date.split()[0]))\n","\n","    return train_data, test_data"],"metadata":{"id":"zMGZAjincGvm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Trading_Environment():\n","    def __init__(self, dataset, verbose=False):\n","        self.window_size = 11\n","        self.state_size = self.window_size\n","        self.action_space = {0: \"Stay\", 1: \"Buy\", 2: \"Sell\"}\n","\n","        self.data = dataset\n","        self.data_length = len(dataset)\n","\n","        self.inventory = None\n","        self.current_step = None\n","\n","        self.verbose = verbose\n","\n","        self.reset()\n","\n","    def reset(self):\n","        self.inventory = []\n","        self.current_step = 0\n","\n","        return self._get_state()\n","\n","    def step(self, action):\n","        reward = 0  # Only increases when selling is positive\n","        profit = 0\n","\n","        current_price = self.data[self.current_step]\n","\n","        if action == 1: # Buying\n","            self.inventory.append(current_price)\n","\n","            if self.verbose:\n","                print(\"Robot-RL {:6s}: {}\".format(\n","                    \"Compró\", self.stock_price_format(current_price)),\n","                    \"Inventario: \", len(self.inventory))\n","\n","        elif action == 2 and len(self.inventory) > 0: # Selling\n","            buy_price = self.inventory.pop(0)\n","\n","            difference = current_price - buy_price\n","\n","            reward = difference  # max(difference, 0)\n","            profit = difference\n","            if self.verbose:\n","                print(\"Robot-RL {:6s}: {}\".format(\n","                    \"Vendió\", self.stock_price_format(current_price)),\n","                    \"Inventario: \", len(self.inventory))\n","\n","        else: # Staying\n","            if self.verbose:\n","                print(\"Robot-RL {:6s}: {}\".format(\n","                    \"Esperó\", self.stock_price_format(current_price)),\n","                    \"Inventario: \", len(self.inventory))\n","\n","        self.current_step += 1\n","        next_state = self._get_state()\n","\n","        if self.current_step >= self.data_length - 1:\n","            done = True\n","        else:\n","            done = False\n","\n","        return next_state, reward, done, profit\n","\n","    def _get_state(self):\n","        # Calculate the starting id\n","        starting_id = self.current_step - self.window_size + 1\n","\n","        # Windowing data\n","        if starting_id >= 0:\n","            windowed_data = self.data[starting_id : self.current_step + 1].tolist()\n","        else:\n","            windowed_data = -starting_id * [self.data[0]] + \\\n","                            list(self.data[0 : self.current_step + 1])\n","\n","        # Normalise price data with sigmoid function\n","        state = 1. / (1. + np.exp(-np.diff(windowed_data)))\n","\n","        # Return observation / state\n","        return np.concatenate(([len(self.inventory) * self.current_value], state))\n","\n","    def get_action_sample(self):\n","        return random.randrange(len(self.action_space))\n","\n","    @property\n","    def current_value(self):\n","        return self.data[self.current_step]\n","\n","    @staticmethod\n","    def stock_price_format(n):\n","        return \"- $ {:10f}, \".format(abs(n)) if n < 0 else \"+ $ {:10f},\".format(abs(n))\n","    "],"metadata":{"id":"QjZpkKnZbqd7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio 1\n"],"metadata":{"id":"FMup3AThckZb"}},{"cell_type":"code","source":["class DQL_Agent():\n","    def __init__(self, environment, agent_name=\"Q_model\", pretrained=False):\n","        self.env = environment\n","        self.memory = deque(maxlen=2000)\n","        self.batch_size = 32\n","        self.agent_name = agent_name\n","\n","        self.gamma = 0.99\n","        self.epsilon = 1.0\n","        self.epsilon_min = 0.01\n","        self.epsilon_decay = 0.995\n","        self.learning_rate = 0.001\n","\n","        self.first_step = True\n","\n","        self.model = self.load_model() if pretrained else self.create_model()\n","\n","\n","    def create_model(self):\n","        model = keras.models.Sequential(name=self.agent_name)\n","\n","        model.add(keras.Input(shape=(self.env.state_size,)))\n","        #model.add(keras.layers.Dense(name=\"Layer1\", units=128, activation='relu'))\n","        #model.add(keras.layers.Dense(name=\"Layer2\", units=256, activation='relu'))\n","        #model.add(keras.layers.Dense(name=\"Layer3\", units=256, activation='relu'))\n","        model.add(keras.layers.Dense(name=\"Layer4\", units=32, activation='relu'))\n","        model.add(keras.layers.Dense(name=\"Layer5\", units=len(self.env.action_space), activation='linear'))\n","\n","        model.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate))\n","        return model\n","\n","    def get_action(self, s, is_evaluating=False):\n","        if self.first_step:\n","            self.first_step = False\n","            return 1\n","\n","        if not is_evaluating and random.random() <= self.epsilon:\n","            return self.env.get_action_sample()\n","\n","        else:\n","            return int(tf.argmax(self.model.predict(\n","                s.reshape(1, self.env.state_size), verbose=0)[0]))\n","\n","    def remember(self, sarsd):\n","        # sarsd: (state, action, reward, new_state, done)\n","        self.memory.append(sarsd)\n","\n","    def experience_replay(self):\n","        batch_sample = random.sample(self.memory, self.batch_size)\n","\n","        states = np.array([sarsd[0] for sarsd in batch_sample])\n","        actions = np.array([sarsd[1] for sarsd in batch_sample])\n","        rewards = np.array([sarsd[2] for sarsd in batch_sample])\n","        next_states = np.array([sarsd[3] for sarsd in batch_sample])\n","        done = np.array([sarsd[4] for sarsd in batch_sample])\n","\n","        # Q predicho\n","        target = rewards + self.gamma * np.amax(self.model.predict(next_states, verbose=0), axis=1)\n","        target[done] = rewards[done]\n","\n","        # Q actual\n","        q_values = self.model.predict(states, verbose=0)\n","        q_values[range(self.batch_size), actions] = target\n","\n","        loss = self.model.fit(states, q_values, epochs=1, verbose=0).history[\"loss\"][0]\n","\n","        \"\"\" Slow version:\n","        states_train = []\n","        q_train = []\n","\n","        for sarsd in batch_sample:\n","            state, action, reward, new_state, done = sarsd\n","\n","            target = reward\n","            if not done:\n","                future_rewards = self.model.predict(new_state.reshape(1, self.env.state_size), verbose=0)[0]\n","                target += self.gamma * np.amax(future_rewards)\n","\n","            q_values = self.model.predict(state.reshape(1, self.env.state_size), verbose=0)\n","\n","            q_values[0][action] = target\n","\n","            states_train.append(state)\n","            q_train.append(q_values[0])\n","\n","        loss = self.model.fit(np.stack(states_train), np.stack(q_train), epochs=1, verbose=0).history[\"loss\"][0]\n","        \"\"\"\n","\n","        self.update_epsilon()\n","\n","        return loss\n","\n","    def update_epsilon(self):\n","        if self.epsilon >= self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","\n","    def save_model(self, episode):\n","        self.model.save(\"models/{}_{}\".format(self.agent_name, episode))\n","\n","    def load_model(self):\n","        return keras.models.load_model(\"models/\" + self.agent_name)"],"metadata":{"id":"RNeHAWTTeh-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data, test_data = dataset_loader(\n","    stock_name=\"AAPL\", clip_data=200, train_portion=0.5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ilBg5hAA4Q6B","executionInfo":{"status":"ok","timestamp":1663056292606,"user_tz":300,"elapsed":1226,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"1a7c3a08-ec59-49ac-ea3e-c6d5f75c7b85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Timeline:\n"," 2021-11-24 <---[101]---> 2022-04-20 <---[100]---> 2022-09-12\n"]}]},{"cell_type":"code","source":["entorno = Trading_Environment(train_data)\n","dql_agent = DQL_Agent(entorno)\n","\n","q_model = dql_agent.create_model()\n","q_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"71xVoM4ufE5p","executionInfo":{"status":"ok","timestamp":1663056295525,"user_tz":300,"elapsed":858,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"5ddd8a95-9822-4da1-b3d9-a1479f2ccbba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"Q_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," Layer4 (Dense)              (None, 32)                384       \n","                                                                 \n"," Layer5 (Dense)              (None, 3)                 99        \n","                                                                 \n","=================================================================\n","Total params: 483\n","Trainable params: 483\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["!pip install visualkeras\n","import visualkeras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CELe1MF9fHPx","executionInfo":{"status":"ok","timestamp":1663056309654,"user_tz":300,"elapsed":5168,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"636471bc-a64b-4fc9-853d-79b76569b746"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting visualkeras\n","  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (1.21.6)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from visualkeras) (7.1.2)\n","Collecting aggdraw>=1.3.11\n","  Downloading aggdraw-1.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (989 kB)\n","\u001b[K     |████████████████████████████████| 989 kB 4.2 MB/s \n","\u001b[?25hInstalling collected packages: aggdraw, visualkeras\n","Successfully installed aggdraw-1.3.15 visualkeras-0.0.2\n"]}]},{"cell_type":"code","source":["visualkeras.layered_view(q_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":44},"id":"8DuNUj7ofJXH","executionInfo":{"status":"ok","timestamp":1663056315304,"user_tz":300,"elapsed":13,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"32047d24-79e7-4700-8340-dc2419f7f100"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PIL.Image.Image image mode=RGBA size=77x27 at 0x7FE2FF03EDD0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAE0AAAAbCAYAAAA53gJaAAACeElEQVR4nO2Z3WtSYRzHv26lskIrDyKyylnUONAL3aWuaFCH6OWum+iuqy7aH1A51l2MaBdBTRgEkTcFQYbTDXpBKhdbEUyFCuXkpNSMM5fKPMydLsI1Z+bZ45me0fncPi/fH5/z8PzgOSpBEAQQMjI8BKfzKmwHjKRbVPAukkH8Wx52hwNms7nmvEwyhkg4DNtB6XJnknl4PB6cOn2m7vwNpEEjw0O4PtCPsTvHsXu7jnSbJfoGJ1DkSzBs1cLlcoGm6X/kjmLsrrS527Zo0WXdJWpNG0lQWZj3dq9khXsDCTy5dQQGvVZ2uStZtbS1LNzauVl2uX9jVdIUYb8RLU0R9geVmO7Zd+kCRr1P0aFph3oj0TVYwUJJwOd4Fof3UdjUUdmLXkymYevphU6nQzz6AZnvKUlzZ38W8fCGvUqY4+JzPPa+rtmAllO3e/I8j7nsLA51Uzh3wkpe8TIejcfQ3gacP7mzamwqwoFhGJhMJrjvfcEOQ0nS3MJ8kfiElakrTa1Ww2LpAvRJyYoPRzkU5nmcPdpZNTZ4/xMYhgFN0/g4/QbggpLmToVTDe/T+Jn/D1GkEaBII0CRRoAijQBFGgGKNAIUaQQo0ghQpBFA/HK7VhT5Evx+P0KhEFiWhUXfnNzFRfGv/rKS5vaxyOYXEAgEoNFokE6wsOzXNCV3rlCC0Sjun4NspLl9LG4+iGHi7Xvs2dsNABi4chnggk3JDbyaBEVRotbI4k4rF/7sZXBJmJxzWy5tvQkDWixtPQoDWigtkS60RJgUuaIaQS6Xg288hkiUIwpZSTjKYSaVh73nGK45+2vO+8pOg/uRkjRXgKrhD/ULD+te9CBF0jUAAAAASUVORK5CYII=\n"},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## Ejercicio 2"],"metadata":{"id":"bVglHNu_fQnL"}},{"cell_type":"code","source":["def train_model(agent, env, num_episodes=10):\n","    profit_evolution = []\n","    reward_evolution = []\n","    average_loss = []\n","\n","    for episode in range(1, num_episodes + 1):\n","\n","        total_profit = 0\n","        total_reward = 0\n","        loss_list = []\n","\n","        state = env.reset()\n","        done = False\n","        while not done:\n","            action = agent.get_action(state)\n","            new_state, reward, done, profit = env.step(action)\n","\n","            sarsd = (state, action, reward, new_state, done)\n","            agent.remember(sarsd)\n","\n","            if len(agent.memory) > agent.batch_size:\n","                loss = agent.experience_replay()\n","                loss_list.append(loss)\n","\n","            state = new_state\n","\n","            total_profit += profit\n","            total_reward += reward\n","\n","            #print(\"Step: {}, Loss: {}, Profit: {}\".format(env.current_step, loss, profit))\n","\n","        print(f\"Episode {episode}, Profit: {total_profit}, Reward: {total_reward}\")\n","\n","        profit_evolution.append(total_profit)\n","        reward_evolution.append(total_reward)\n","        if len(loss_list) > 0:\n","            average_loss.append(np.mean(np.array(loss_list)))\n","\n","        if episode % 10 == 0:\n","            agent.save_model(f\"{episode}\")\n","\n","    agent.save_model(f\"{num_episodes}\")\n","    return profit_evolution, reward_evolution, average_loss"],"metadata":{"id":"mrxBUBMV3WM0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio 3"],"metadata":{"id":"z1kenJi3eLIp"}},{"cell_type":"code","source":["train_data, test_data = dataset_loader(\"AAPL\", 200, 0.5)"],"metadata":{"id":"WIONL5TX3Yla","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663056328055,"user_tz":300,"elapsed":1493,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"b7536f95-108d-4dfb-e55b-a17bec2af2a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Timeline:\n"," 2021-11-24 <---[101]---> 2022-04-20 <---[100]---> 2022-09-12\n"]}]},{"cell_type":"code","source":["entorno = Trading_Environment(train_data)\n","agente = DQL_Agent(environment=entorno, agent_name=\"robot_d2ql\")\n","\n","pev, rev, avl = train_model(agent=agente, env=entorno, num_episodes=30)"],"metadata":{"id":"vq-h7U2_3aZO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663056888224,"user_tz":300,"elapsed":558126,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"dcc385e5-8f4e-48c6-9b9e-cf2bdd9af04a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 1, Profit: 20.240020751953125, Reward: 20.240020751953125\n","Episode 2, Profit: -21.0799560546875, Reward: -21.0799560546875\n","Episode 3, Profit: -82.37998962402344, Reward: -82.37998962402344\n","Episode 4, Profit: 70.61000061035156, Reward: 70.61000061035156\n","Episode 5, Profit: -114.11997985839844, Reward: -114.11997985839844\n","Episode 6, Profit: 49.8699951171875, Reward: 49.8699951171875\n","Episode 7, Profit: 7.9499969482421875, Reward: 7.9499969482421875\n","Episode 8, Profit: 21.550003051757812, Reward: 21.550003051757812\n","Episode 9, Profit: 0, Reward: 0\n","Episode 10, Profit: 0, Reward: 0\n","Episode 11, Profit: 0, Reward: 0\n","Episode 12, Profit: 0, Reward: 0\n","Episode 13, Profit: 0, Reward: 0\n","Episode 14, Profit: -9.559982299804688, Reward: -9.559982299804688\n","Episode 15, Profit: 17.729995727539062, Reward: 17.729995727539062\n","Episode 16, Profit: 0, Reward: 0\n","Episode 17, Profit: 0, Reward: 0\n","Episode 18, Profit: -15.279998779296875, Reward: -15.279998779296875\n","Episode 19, Profit: 0, Reward: 0\n","Episode 20, Profit: 0, Reward: 0\n","Episode 21, Profit: -9.809982299804688, Reward: -9.809982299804688\n","Episode 22, Profit: 0, Reward: 0\n","Episode 23, Profit: 0, Reward: 0\n","Episode 24, Profit: 84.02000427246094, Reward: 84.02000427246094\n","Episode 25, Profit: -54.709991455078125, Reward: -54.709991455078125\n","Episode 26, Profit: -51.579986572265625, Reward: -51.579986572265625\n","Episode 27, Profit: 0, Reward: 0\n","Episode 28, Profit: -33.910003662109375, Reward: -33.910003662109375\n","Episode 29, Profit: 0, Reward: 0\n","Episode 30, Profit: -1.0500030517578125, Reward: -1.0500030517578125\n"]}]},{"cell_type":"code","source":["x_list = np.arange(len(pev))\n","\n","fig1 = make_subplots(rows=2, cols=1, shared_xaxes=True)\n","\n","fig1.add_trace(go.Scatter(x=x_list, y=pev, mode='lines', name=\"Profit Evolution\", \n","                          opacity=1), row=1, col=1)\n","fig1.add_trace(go.Scatter(x=x_list, y=pev, mode='lines', name=\"Reward Evolution\", \n","                          opacity=0.5), row=1, col=1)\n","\n","fig1.add_trace(go.Scatter(x=x_list, y=avl, mode='lines', name=\"Average Loss\", \n","                          opacity=1), row=2, col=1)\n","\n","fig1.update_xaxes(title_text=\"Episode\")\n","fig1.show()"],"metadata":{"id":"cGfQJnvD3c_A","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1663056924114,"user_tz":300,"elapsed":772,"user":{"displayName":"Jorge Mario Cruz Duarte","userId":"13516284558844055913"}},"outputId":"4612a82b-a69b-435c-d2f0-ef0bc3d756a8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b2bad3d0-27be-466f-bc9c-1c12c91e146d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b2bad3d0-27be-466f-bc9c-1c12c91e146d\")) {                    Plotly.newPlot(                        \"b2bad3d0-27be-466f-bc9c-1c12c91e146d\",                        [{\"mode\":\"lines\",\"name\":\"Profit Evolution\",\"opacity\":1,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[20.240020751953125,-21.0799560546875,-82.37998962402344,70.61000061035156,-114.11997985839844,49.8699951171875,7.9499969482421875,21.550003051757812,0,0,0,0,0,-9.559982299804688,17.729995727539062,0,0,-15.279998779296875,0,0,-9.809982299804688,0,0,84.02000427246094,-54.709991455078125,-51.579986572265625,0,-33.910003662109375,0,-1.0500030517578125],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Reward Evolution\",\"opacity\":0.5,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[20.240020751953125,-21.0799560546875,-82.37998962402344,70.61000061035156,-114.11997985839844,49.8699951171875,7.9499969482421875,21.550003051757812,0,0,0,0,0,-9.559982299804688,17.729995727539062,0,0,-15.279998779296875,0,0,-9.809982299804688,0,0,84.02000427246094,-54.709991455078125,-51.579986572265625,0,-33.910003662109375,0,-1.0500030517578125],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"mode\":\"lines\",\"name\":\"Average Loss\",\"opacity\":1,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[1066.5068229226506,44.25075456142426,425.5432306098938,625.3226915740967,4491.613347015381,2269.8768551635744,1910.4522792053222,4177.227965774536,3477.588935089111,3947.07656539917,3009.276052322388,5111.134850845337,3757.0868215179444,9292.619459838867,6334.191678695679,3988.068626251221,2652.3131579589844,1738.8875667953491,1483.408206615448,1155.354430732727,2044.9684251403808,810.813269290924,1050.8533136749268,1341.9184892082214,518.6611264514924,466.66851922035215,440.74794484615325,192.84956508159638,299.81674533843994,285.4330050134659],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"matches\":\"x2\",\"showticklabels\":false,\"title\":{\"text\":\"Episode\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Episode\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.425]}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('b2bad3d0-27be-466f-bc9c-1c12c91e146d');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]}]}